syntax = "proto3";

package mEngine.inference;

import "cud_buffer_config.proto";

// Data layout, or format, of the input/output tensors.
enum TrtTensorFormat {
    TRT_TENSOR_FORMAT_UNSPECIFIED = 0;
    // Row major linear format. For a tensor with dimensions {N, C, H, W} or
    // {numbers, channels, columns, rows}, the dimensional index corresponds to
    // {3, 2, 1, 0} and thus the order is W minor.
    // For DLA usage, the tensor sizes are limited to C,H,W in the range [1,8192].
    TRT_TENSOR_FORMAT_LINEAR = 1;
    // Two wide channel vectorized row major format. This format is bound to FP16.
    // It is only available for dimensions >= 3. For a tensor with dimensions {N,
    // C, H, W}, the memory layout is equivalent to a C array with dimensions
    // [N][(C+1)/2][H][W][2], with the tensor coordinates (n, c, h, w) mapping to
    // array subscript [n][c/2][h][w][c%2].
    TRT_TENSOR_FORMAT_CHW2 = 2;
    // Eight channel format where C is padded to a multiple of 8. This format is
    // bound to FP16. It is only available for dimensions >= 3. For a tensor with
    // dimensions {N, C, H, W}, the memory layout is equivalent to the array with
    // dimensions [N][H][W][(C+7)/8*8], with the tensor coordinates (n, c, h, w)
    // mapping to array subscript [n][h][w][c].
    TRT_TENSOR_FORMAT_HWC8 = 3;
    // Four wide channel vectorized row major format. This format is bound to INT8
    // or FP16. It is only available for dimensions >= 3. For INT8, the C
    // dimension must be a build-time constant. For a tensor with dimensions {N,
    // C, H, W}, the memory layout is equivalent to a C array with dimensions
    // [N][(C+3)/4][H][W][4], with the tensor coordinates (n, c, h, w) mapping to
    // array subscript [n][c/4][h][w][c%4].
    TRT_TENSOR_FORMAT_CHW4 = 4;
    // Sixteen wide channel vectorized row major format. This format is bound to
    // FP16. It is only available for dimensions >= 3. For a tensor with
    // dimensions {N, C, H, W}, the memory layout is equivalent to a C array with
    // dimensions [N][(C+15)/16][H][W][16], with the tensor coordinates (n, c, h,
    // w) mapping to array subscript [n][c/16][h][w][c%16].
    // For DLA usage, this format maps to the native image format for FP16, and
    // the tensor sizes are limited to C,H,W in the range [1,8192].
    TRT_TENSOR_FORMAT_CHW16 = 5;
    // Thirty-two wide channel vectorized row major format. This format is only
    // available for dimensions >= 3. For a tensor with dimensions {N, C, H, W},
    // the memory layout is equivalent to a C array with dimensions
    // [N][(C+31)/32][H][W][32], with the tensor coordinates (n, c, h, w) mapping
    // to array subscript [n][c/32][h][w][c%32]. For DLA usage, this format maps
    // to the native image format for INT8, and the tensor sizes are limited to
    // C,H,W in the range [1,8192].
    TRT_TENSOR_FORMAT_CHW32 = 6;
    // Eight channel format where C is padded to a multiple of 8. This format is
    // bound to FP16, and it is only available for dimensions >= 4. For a tensor
    // with dimensions {N, C, D, H, W}, the memory layout is equivalent to an
    // array with dimensions [N][D][H][W][(C+7)/8*8], with the tensor coordinates
    // (n, c, d, h, w) mapping to array subscript [n][d][h][w][c].
    TRT_TENSOR_FORMAT_DHWC8 = 7;
    // Thirty-two wide channel vectorized row major format. This format is bound
    // to FP16 and INT8 and is only available for dimensions >= 4. For a tensor
    // with dimensions {N, C, D, H, W}, the memory layout is equivalent to a C
    // array with dimensions [N][(C+31)/32][D][H][W][32], with the tensor
    // coordinates (n, c, d, h, w) mapping to array subscript
    // [n][c/32][d][h][w][c%32].
    TRT_TENSOR_FORMAT_CDHW32 = 8;
    // Non-vectorized channel-last format. This format is bound to FP32 and is
    // only available for dimensions >= 3.
    TRT_TENSOR_FORMAT_HWC = 9;
    // DLA planar format. For a tensor with dimension {N, C, H, W}, the W axis
    // always has unit stride. The stride for stepping along the H axis is rounded
    // up to 64 bytes.
    // The memory layout is equivalent to a C array with dimensions
    // [N][C][H][roundUp(W, 64/elementSize)] where elementSize is 2 for FP16 and 1
    // for Int8, with the tensor coordinates (n, c, h, w) mapping to array
    // subscript [n][c][h][w].
    TRT_TENSOR_FORMAT_DLA_LINEAR = 10;
    // DLA image format. For a tensor with dimension {N, C, H, W} the C axis
    // always has unit stride. The stride for stepping along the H axis is rounded
    // up to 32 bytes on Xavier and 64 bytes on Orin. C can only be 1, 3 or 4. If
    // C == 1, it will map to grayscale format. If C == 3 or C == 4, it will map
    // to color image format. And if C == 3, the stride for stepping along the W
    // axis needs to be padded to 4 in elements.
    //
    // When C is {1, 3, 4}, then C' is {1, 4, 4} respectively, the memory layout
    // is equivalent to a C array with dimensions [N][H][roundUp(W,
    // 32/C'/elementSize)][C'] where elementSize is 2 for FP16 and 1 for Int8. The
    // tensor coordinates (n, c, h, w) mapping to array subscript [n][h][w][c].
    TRT_TENSOR_FORMAT_DLA_HWC4 = 11;
    // Sixteen channel format where C is padded to a multiple of 16. This format
    // is bound to FP16. It is only available for dimensions >= 3. For a tensor
    // with dimensions {N, C, H, W}, the memory layout is equivalent to the array
    // with dimensions [N][H][W][(C+15)/16*16], with the tensor coordinates (n, c,
    // h, w) mapping to array subscript [n][h][w][c].
    TRT_TENSOR_FORMAT_HWC16 = 12;
}

// Definition of tensor IO Mode.
enum TrtIOMode {
    TRT_IOMODE_UNSPECIFIED = 0;
    // Tensor is not an input or output.
    TRT_IOMODE_NONE = 1;
    // Tensor is input to the engine.
    TRT_IOMODE_INPUT = 2;
    // Tensor is output by the engine.
    TRT_IOMODE_OUTPUT = 3;
}

// Structure to define the dimensions of a tensor.
message TrtTensorDims {
    // -1 of a dimension means dynamic shape on that axis.
    repeated int32 dims = 1;
}

// When setting or querying optimization profile parameters (such as shape
// tensor inputs or dynamic dimensions), select whether we are interested in the
// minimum, optimum, or maximum values for these parameters. The minimum and
// maximum specify the permitted range that is supported at runtime, while the
// optimum value is used for the kernel selection. This should be the "typical"
// value that is expected to occur at runtime.
message TrtOptimizationProfile {
    TrtTensorDims min = 1;
    TrtTensorDims opt = 2;
    TrtTensorDims max = 3;
}

// Configurations for the input/output tensor of the model/network.
message TrtIOConfig {
    // Name of the input/output tensor.
    // This name will be used as a unique identifier across the
    // conversion/calibration/inference phases. This name should be identical to
    // the ONNX input model.
    string name = 1;
    // Human readable descriptions of the I/O tensor.
    string description = 2;
    // Data type of the I/O tensor
    mEngine.cuda_buffer.DataType data_type = 3;
    // Tensor data layout/format.
    TrtTensorFormat tensor_format = 4;
    // During engine conversion phase, it would be ignored for verification
    // purposes, e.g., `DEVICE_ONLY` might be overriden as `HOST_AND_DEVICE`.
    mEngine.cuda_buffer.BufferLocation tensor_location = 5;
    // Require that no reformats be inserted between a layer and a network I/O
    // tensor. Build might fail if a reformat is required for functional
    // correctness.
    bool direct_io = 6;
    // Multiple opt profiles might exist for the same engine.
    repeated TrtOptimizationProfile optimization_profiles = 7;
    // Sometimes we might have auxiliary output tensors for developing/debugging
    // purposes, set this field to true will remove such auxiliary output
    // tensors in the production environment.
    bool suppressed = 8;
}
